{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 256 x 256 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b0c944e28d4fb7900a3522ccf25f56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc0041c3d65413e8799c8bd87ad16ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import AmusedPipeline\n",
    "\n",
    "pipe = AmusedPipeline.from_pretrained(\n",
    "    \"amused/amused-256\", variant=\"fp16\", torch_dtype=torch.float16\n",
    ")\n",
    "pipe.vqvae.to(torch.float32)  # vqvae is producing nans in fp16\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"cute anime girl face, blue eyes and pretty face\"\n",
    "image = pipe(prompt, generator=torch.Generator('cuda').manual_seed(8)).images[0]\n",
    "image.save('./data/text2image_256.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 512 x 512 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45445751d0d54fcdb51eabb0e89698cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68a43486a134aa6ba56330ea45a71b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import AmusedPipeline\n",
    "\n",
    "pipe = AmusedPipeline.from_pretrained(\n",
    "    \"amused/amused-512\", variant=\"fp16\", torch_dtype=torch.float16\n",
    ")\n",
    "pipe.vqvae.to(torch.float32)  # vqvae is producing nans n fp16\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"cute anime girl face, blue eyes and pretty face\"\n",
    "image = pipe(prompt, generator=torch.Generator('cuda').manual_seed(42)).images[0]\n",
    "image.save('./data/text2image_512.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image-to-Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4662225aca924e7e84d3df4c7b5564b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6b29e2197f43008abe7c432a4df8b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import AmusedImg2ImgPipeline\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "pipe = AmusedImg2ImgPipeline.from_pretrained(\n",
    "    \"amused/amused-256\", variant=\"fp16\", torch_dtype=torch.float16\n",
    ")\n",
    "pipe.vqvae.to(torch.float32)  # vqvae is producing nans in fp16\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"apple watercolor\"\n",
    "input_image = (\n",
    "    load_image(\n",
    "        \"https://raw.githubusercontent.com/huggingface/amused/main/assets/image2image_256_orig.png\"\n",
    "    )\n",
    "    .resize((256, 256))\n",
    "    .convert(\"RGB\")\n",
    ")\n",
    "\n",
    "image = pipe(prompt, input_image, strength=0.7, generator=torch.Generator('cuda').manual_seed(3)).images[0]\n",
    "image.save('./data/image2image_256.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inpainting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 256 x 256 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8ade3d17614c1696f3df7322250c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ce7676ccfb74c3a91b4e13bbd72c490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a907800b62749eaa2f77b952e825571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3a4fb696a2c4c4999e4774f7230eb3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2cba3a915c947809c86faac2dcd5a1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeec583901084021bc8320e14ef62980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce422144d9a41ab903bd08a8894d2cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8fb45a2005423f999c8e61eda2ad75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614c4b521e77459eb9e3a2a167133e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4304404d0114bceaf16ab6c22c7ff27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d614b2a256243e1b81db3cf938e7218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e09c85e54eb14d35ac386a94daed27d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf40a54a88342d699c2434848b7edbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd43a27a19d407b8f5a715f75a64029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8798e91510a84487a255f9450ec0b003",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b7aaa8fca044b88949714a361929a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f003333178c54a8e91f9b0589f4af87d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d6e6819ddd64a7baa092d2b369e5b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bafc77236ce4b9daa5fa764af8755c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d16629417c4fbda0696d64bb75483c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33769f79b334344a761a0fbca5eba22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import AmusedInpaintPipeline\n",
    "from diffusers.utils import load_image\n",
    "from PIL import Image\n",
    "\n",
    "pipe = AmusedInpaintPipeline.from_pretrained(\n",
    "    \"amused/amused-256\", variant=\"fp16\", torch_dtype=torch.float16\n",
    ")\n",
    "pipe.vqvae.to(torch.float32)  # vqvae is producing nans in fp16\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"a man with glasses\"\n",
    "input_image = (\n",
    "    load_image(\n",
    "        \"https://raw.githubusercontent.com/huggingface/amused/main/assets/inpainting_256_orig.png\"\n",
    "    )\n",
    "    .resize((256, 256))\n",
    "    .convert(\"RGB\")\n",
    ")\n",
    "mask = (\n",
    "    load_image(\n",
    "        \"https://raw.githubusercontent.com/huggingface/amused/main/assets/inpainting_256_mask.png\"\n",
    "    )\n",
    "    .resize((256, 256))\n",
    "    .convert(\"L\")\n",
    ")    \n",
    "\n",
    "input_image.save(f'./data/inpainting_256_original.png')\n",
    "mask.save(f'./data/inpainting_256_mask.png')\n",
    "\n",
    "for seed in range(20):\n",
    "    image = pipe(prompt, input_image, mask, generator=torch.Generator('cuda').manual_seed(seed)).images[0]\n",
    "    image.save(f'./data/inpainting_256_{seed}.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 512 x 512 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d820604f6e134e7188734600289b742f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aea56144aa734245a19a215b3785be71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import AmusedInpaintPipeline\n",
    "from diffusers.utils import load_image\n",
    "\n",
    "pipe = AmusedInpaintPipeline.from_pretrained(\n",
    "    \"amused/amused-512\", variant=\"fp16\", torch_dtype=torch.float16\n",
    ")\n",
    "pipe.vqvae.to(torch.float32)  # vqvae is producing nans in fp16\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"fall mountains\"\n",
    "input_image = (\n",
    "    load_image(\n",
    "        \"https://raw.githubusercontent.com/huggingface/amused/main/assets/inpainting_512_orig.jpeg\"\n",
    "    )\n",
    "    .resize((512, 512))\n",
    "    .convert(\"RGB\")\n",
    ")\n",
    "mask = (\n",
    "    load_image(\n",
    "        \"https://raw.githubusercontent.com/huggingface/amused/main/assets/inpainting_512_mask.png\"\n",
    "    )\n",
    "    .resize((512, 512))\n",
    "    .convert(\"L\")\n",
    ")\n",
    "\n",
    "input_image.save(f'./data/inpainting_512_original.png')\n",
    "mask.save(f'./data/inpainting_512_mask.png')\n",
    "\n",
    "image = pipe(prompt, input_image, mask, generator=torch.Generator('cuda').manual_seed(0)).images[0]\n",
    "image.save('./data/inpainting_512.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiled Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfd256db08254819ae05d005fa017166",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a18d3616d34cabb6c4b12b56cb3811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from diffusers import AmusedPipeline\n",
    "\n",
    "pipe = AmusedPipeline.from_pretrained(\n",
    "    \"amused/amused-256\", variant=\"fp16\", torch_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# HERE use torch.compile\n",
    "pipe.transformer = torch.compile(pipe.transformer)\n",
    "\n",
    "pipe.vqvae.to(torch.float32)  # vqvae is producing nans in fp16\n",
    "pipe = pipe.to(\"cuda\")\n",
    "\n",
    "prompt = \"cowboy\"\n",
    "image = pipe(prompt, generator=torch.Generator('cuda').manual_seed(8)).images[0]\n",
    "image.save('./data/text2image_256.png')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HPRNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
