{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNjBLwaJzzf1OacXioIpI0W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VimukthiRandika1997/Computer-Vision/blob/dev/Diffusers/Key_Locked_Rank_One_Editing_for_Text_to_Image_Personalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "Sq3PmtKFGxFt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SfbAdlz2vdor",
        "outputId": "3878c938-991c-46ea-b9e1-d38a527a695c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==2.0.0\n",
            "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
            "Collecting torchvision==0.15.1\n",
            "  Downloading torchvision-0.15.1-cp310-cp310-manylinux1_x86_64.whl.metadata (11 kB)\n",
            "Collecting torchaudio==2.0.1\n",
            "  Downloading torchaudio-2.0.1-cp310-cp310-manylinux1_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.0.0 (from torch==2.0.0)\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1) (10.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.44.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0) (3.30.4)\n",
            "Collecting lit (from triton==2.0.0->torch==2.0.0)\n",
            "  Downloading lit-18.1.8-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0) (3.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0) (1.3.0)\n",
            "Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.15.1-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.0.1-cp310-cp310-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/96.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.4.1+cu121\n",
            "    Uninstalling torch-2.4.1+cu121:\n",
            "      Successfully uninstalled torch-2.4.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.19.1+cu121\n",
            "    Uninstalling torchvision-0.19.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.19.1+cu121\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.4.1+cu121\n",
            "    Uninstalling torchaudio-2.4.1+cu121:\n",
            "      Successfully uninstalled torchaudio-2.4.1+cu121\n",
            "Successfully installed lit-18.1.8 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.0 torchaudio-2.0.1 torchvision-0.15.1 triton-2.0.0\n",
            "Collecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-903kd5db\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-903kd5db\n",
            "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting xformers==0.0.19\n",
            "  Downloading xformers-0.0.19-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting albumentations==1.3.1\n",
            "  Downloading albumentations-1.3.1-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting omegaconf==2.1.1\n",
            "  Downloading omegaconf-2.1.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting einops==0.6.1\n",
            "  Downloading einops-0.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting transformers==4.31.0\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl.metadata (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kornia==0.7.0\n",
            "  Downloading kornia-0.7.0-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting open_clip_torch==2.20.0\n",
            "  Downloading open_clip_torch-2.20.0-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers==0.0.19) (1.26.4)\n",
            "Collecting pyre-extensions==0.0.29 (from xformers==0.0.19)\n",
            "  Downloading pyre_extensions-0.0.29-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: torch==2.0.0 in /usr/local/lib/python3.10/dist-packages (from xformers==0.0.19) (2.0.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (1.13.1)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (0.24.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (6.0.2)\n",
            "Collecting qudida>=0.0.4 (from albumentations==1.3.1)\n",
            "  Downloading qudida-0.0.4-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.1) (4.10.0.84)\n",
            "Collecting antlr4-python3-runtime==4.8 (from omegaconf==2.1.1)\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (0.24.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (24.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (2.32.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.31.0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.31.0) (4.66.5)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from open_clip_torch==2.20.0) (0.15.1)\n",
            "Collecting ftfy (from open_clip_torch==2.20.0)\n",
            "  Downloading ftfy-6.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from open_clip_torch==2.20.0) (0.2.0)\n",
            "Requirement already satisfied: protobuf<4 in /usr/local/lib/python3.10/dist-packages (from open_clip_torch==2.20.0) (3.20.3)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.10/dist-packages (from open_clip_torch==2.20.0) (1.0.10)\n",
            "Collecting typing-inspect (from pyre-extensions==0.0.29->xformers==0.0.19)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyre-extensions==0.0.29->xformers==0.0.19) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->xformers==0.0.19) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->xformers==0.0.19) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->xformers==0.0.19) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->xformers==0.0.19) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->xformers==0.0.19) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->xformers==0.0.19) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->xformers==0.0.19) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->xformers==0.0.19) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->xformers==0.0.19) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->xformers==0.0.19) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->xformers==0.0.19) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->xformers==0.0.19) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->xformers==0.0.19) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->xformers==0.0.19) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0->xformers==0.0.19) (2.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->xformers==0.0.19) (75.1.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->xformers==0.0.19) (0.44.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->xformers==0.0.19) (3.30.4)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0->xformers==0.0.19) (18.1.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.31.0) (2024.6.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations==1.3.1) (1.5.2)\n",
            "Requirement already satisfied: pillow>=9.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (10.4.0)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (2024.9.20)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.1) (0.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy->open_clip_torch==2.20.0) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.31.0) (2024.8.30)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.1) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0->xformers==0.0.19) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0->xformers==0.0.19) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect->pyre-extensions==0.0.29->xformers==0.0.19)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading xformers-0.0.19-cp310-cp310-manylinux2014_x86_64.whl (108.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.2/108.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading albumentations-1.3.1-py3-none-any.whl (125 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.7/125.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.7/74.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m112.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kornia-0.7.0-py2.py3-none-any.whl (705 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.7/705.7 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading open_clip_torch-2.20.0-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyre_extensions-0.0.29-py3-none-any.whl (12 kB)\n",
            "Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
            "Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, clip\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141214 sha256=c5bcd13f8f92dd97333435598dbc9b42f166a4197b6b010326de4201c79c2a9e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369489 sha256=a345b97d45f25c80663eb5f2290b09c08448aa953feb74465550d60f937d56d2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-500v698_/wheels/da/2b/4c/d6691fa9597aac8bb85d2ac13b112deb897d5b50f5ad9a37e4\n",
            "Successfully built antlr4-python3-runtime clip\n",
            "Installing collected packages: tokenizers, antlr4-python3-runtime, omegaconf, mypy-extensions, ftfy, einops, typing-inspect, transformers, qudida, pyre-extensions, albumentations, xformers, open_clip_torch, kornia, clip\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.19.1\n",
            "    Uninstalling tokenizers-0.19.1:\n",
            "      Successfully uninstalled tokenizers-0.19.1\n",
            "  Attempting uninstall: einops\n",
            "    Found existing installation: einops 0.8.0\n",
            "    Uninstalling einops-0.8.0:\n",
            "      Successfully uninstalled einops-0.8.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.44.2\n",
            "    Uninstalling transformers-4.44.2:\n",
            "      Successfully uninstalled transformers-4.44.2\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.4.15\n",
            "    Uninstalling albumentations-1.4.15:\n",
            "      Successfully uninstalled albumentations-1.4.15\n",
            "Successfully installed albumentations-1.3.1 antlr4-python3-runtime-4.8 clip-1.0 einops-0.6.1 ftfy-6.3.0 kornia-0.7.0 mypy-extensions-1.0.0 omegaconf-2.1.1 open_clip_torch-2.20.0 pyre-extensions-0.0.29 qudida-0.0.4 tokenizers-0.13.3 transformers-4.31.0 typing-inspect-0.9.0 xformers-0.0.19\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "448542bcec3544edbfb840474861bcdb"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Install dependencies\n",
        "! pip install torch==2.0.0 torchvision==0.15.1 torchaudio==2.0.1\n",
        "! pip install xformers==0.0.19 albumentations==1.3.1 omegaconf==2.1.1 einops==0.6.1 transformers==4.31.0 kornia==0.7.0 open_clip_torch==2.20.0 git+https://github.com/openai/CLIP.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pip==24.0\n",
        "!pip install pillow==9.1.0\n",
        "!pip install pytorch-lightning==1.6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeWToUcE8n35",
        "outputId": "33130472-4f51-4869-c312-3ffaf1cc3cdc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-lightning==1.6.0\n",
            "  Using cached pytorch_lightning-1.6.0-py3-none-any.whl.metadata (33 kB)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.0) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.0) (2.0.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.0) (4.66.5)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.0) (6.0.2)\n",
            "Requirement already satisfied: fsspec!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (2024.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.0) (2.17.0)\n",
            "Collecting torchmetrics>=0.4.1 (from pytorch-lightning==1.6.0)\n",
            "  Using cached torchmetrics-1.5.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting pyDeprecate<0.4.0,>=0.3.1 (from pytorch-lightning==1.6.0)\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.0) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.0) (4.12.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (3.10.10)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (3.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.0) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.0) (3.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.0) (3.1.4)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.0) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.0) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.0) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.0) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.0) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.0) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.0) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.0) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.0) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.0) (2.0.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.8.*->pytorch-lightning==1.6.0) (0.44.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.*->pytorch-lightning==1.6.0) (3.30.4)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.*->pytorch-lightning==1.6.0) (18.1.8)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics>=0.4.1->pytorch-lightning==1.6.0)\n",
            "  Using cached lightning_utilities-0.11.8-py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (1.15.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (3.0.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.*->pytorch-lightning==1.6.0) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (3.10)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (0.2.0)\n",
            "Downloading pytorch_lightning-1.6.0-py3-none-any.whl (582 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m582.1/582.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Downloading torchmetrics-1.5.0-py3-none-any.whl (890 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.5/890.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached lightning_utilities-0.11.8-py3-none-any.whl (26 kB)\n",
            "\u001b[33mDEPRECATION: pytorch-lightning 1.6.0 has a non-standard dependency specifier torch>=1.8.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: pyDeprecate, lightning-utilities, torchmetrics, pytorch-lightning\n",
            "Successfully installed lightning-utilities-0.11.8 pyDeprecate-0.3.2 pytorch-lightning-1.6.0 torchmetrics-1.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/ChenDarYen/Key-Locked-Rank-One-Editing-for-Text-to-Image-Personalization.git\n",
        "%cd Key-Locked-Rank-One-Editing-for-Text-to-Image-Personalization"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ww6cSJsR-020",
        "outputId": "4270a409-fd45-4620-861c-593d351871cb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Key-Locked-Rank-One-Editing-for-Text-to-Image-Personalization' already exists and is not an empty directory.\n",
            "/content/Key-Locked-Rank-One-Editing-for-Text-to-Image-Personalization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download pretrained checkpoints\n",
        "%cd ./ckpt\n",
        "!wget https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSgfgk9l2px8",
        "outputId": "8407ed9a-3a64-4147-af73-d3439e11d60b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Key-Locked-Rank-One-Editing-for-Text-to-Image-Personalization/ckpt\n",
            "--2024-10-19 13:42:08--  https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.16, 18.239.50.80, 18.239.50.49, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 307 Temporary Redirect\n",
            "Location: /stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt [following]\n",
            "--2024-10-19 13:42:08--  https://huggingface.co/stable-diffusion-v1-5/stable-diffusion-v1-5/resolve/main/v1-5-pruned-emaonly.ckpt\n",
            "Reusing existing connection to huggingface.co:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/66/6f/666f465fa70158515404e8de2c6bc6fe2f90c46f9296293aa14daededeb32c52/cc6cb27103417325ff94f52b7a5d2dde45a7515b25c255d8e396c90014281516?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27v1-5-pruned-emaonly.ckpt%3B+filename%3D%22v1-5-pruned-emaonly.ckpt%22%3B&Expires=1729602784&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyOTYwMjc4NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy82Ni82Zi82NjZmNDY1ZmE3MDE1ODUxNTQwNGU4ZGUyYzZiYzZmZTJmOTBjNDZmOTI5NjI5M2FhMTRkYWVkZWRlYjMyYzUyL2NjNmNiMjcxMDM0MTczMjVmZjk0ZjUyYjdhNWQyZGRlNDVhNzUxNWIyNWMyNTVkOGUzOTZjOTAwMTQyODE1MTY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=XfKNBeW43Cx9kKPETvp9Fw8EGyTkpLqxbHwLWUZF%7Evwg2e2manfHfnKHCqp7oerFxt92NhSu7YIA51QY-vgPzPIO6LqEbumC5TMfQ2FeuooPvL6rg3LLb49YN8GYnmRs2oY1rw1ZWkU4zpRTbhKU-QoQgYcoOguAK5hTgNChihGRB1N9xcweIGpyuqVzmVYVvNhdcXpSoY2i3g5E-sB9JfkU4wSMkC%7Eske6gwfARz%7EPE4arxvSgFVzFBGSTPMejB-lsCz%7EYo8bZeQ0rk0ABXKwAoDpLpXRxYlS0kDs72wyFYLphVOmgAbBdDreyX9BSj8nJPyN2rX1BdSrcBeUU-yQ__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2024-10-19 13:42:08--  https://cdn-lfs.hf.co/repos/66/6f/666f465fa70158515404e8de2c6bc6fe2f90c46f9296293aa14daededeb32c52/cc6cb27103417325ff94f52b7a5d2dde45a7515b25c255d8e396c90014281516?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27v1-5-pruned-emaonly.ckpt%3B+filename%3D%22v1-5-pruned-emaonly.ckpt%22%3B&Expires=1729602784&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyOTYwMjc4NH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy82Ni82Zi82NjZmNDY1ZmE3MDE1ODUxNTQwNGU4ZGUyYzZiYzZmZTJmOTBjNDZmOTI5NjI5M2FhMTRkYWVkZWRlYjMyYzUyL2NjNmNiMjcxMDM0MTczMjVmZjk0ZjUyYjdhNWQyZGRlNDVhNzUxNWIyNWMyNTVkOGUzOTZjOTAwMTQyODE1MTY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=XfKNBeW43Cx9kKPETvp9Fw8EGyTkpLqxbHwLWUZF%7Evwg2e2manfHfnKHCqp7oerFxt92NhSu7YIA51QY-vgPzPIO6LqEbumC5TMfQ2FeuooPvL6rg3LLb49YN8GYnmRs2oY1rw1ZWkU4zpRTbhKU-QoQgYcoOguAK5hTgNChihGRB1N9xcweIGpyuqVzmVYVvNhdcXpSoY2i3g5E-sB9JfkU4wSMkC%7Eske6gwfARz%7EPE4arxvSgFVzFBGSTPMejB-lsCz%7EYo8bZeQ0rk0ABXKwAoDpLpXRxYlS0kDs72wyFYLphVOmgAbBdDreyX9BSj8nJPyN2rX1BdSrcBeUU-yQ__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 18.65.39.84, 18.65.39.123, 18.65.39.121, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|18.65.39.84|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4265380512 (4.0G) [binary/octet-stream]\n",
            "Saving to: ‘v1-5-pruned-emaonly.ckpt.1’\n",
            "\n",
            "v1-5-pruned-emaonly 100%[===================>]   3.97G   253MB/s    in 20s     \n",
            "\n",
            "2024-10-19 13:42:28 (203 MB/s) - ‘v1-5-pruned-emaonly.ckpt.1’ saved [4265380512/4265380512]\n",
            "\n",
            "/content/Key-Locked-Rank-One-Editing-for-Text-to-Image-Personalization\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "xqFl6DTvGvEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change line 59 in /content/Key-Locked-Rank-One-Editing-for-Text-to-Image-Personalization/perfusion/dataset.py\n",
        "# for new PIL version to BILINEAR"
      ],
      "metadata": {
        "id": "TUoMQxHeEsgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! python main.py \\\n",
        "      --name teddy \\\n",
        "      --base ./configs/perfusion_teddy.yaml \\\n",
        "      --basedir ./ckpt \\\n",
        "      -t True \\\n",
        "      --gpus 0,"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qGXyaPg-8iF",
        "outputId": "8eb774ae-08a3-4c8c-aebc-82870816e9f2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-19 13:54:16.987110: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-19 13:54:17.015239: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-19 13:54:17.023865: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-19 13:54:18.787941: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Global seed set to 2023\n",
            "Running on GPUs 0,\n",
            "Perfusion: Running in eps-prediction mode\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
            "DiffusionWrapper has 861.44 M params.\n",
            "making attention of type 'vanilla-xformers' with 512 in_channels\n",
            "building MemoryEfficientAttnBlock with 512 in_channels...\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "making attention of type 'vanilla-xformers' with 512 in_channels\n",
            "building MemoryEfficientAttnBlock with 512 in_channels...\n",
            "Restored from ./ckpt/v1-5-pruned-emaonly.ckpt with 37 missing and 3 unexpected keys\n",
            "Missing Keys:\n",
            " ['logvar', 'C_inv', 'target_input', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_k.target_output', 'model.diffusion_model.input_blocks.1.1.transformer_blocks.0.attn2.to_v.target_output', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_k.target_output', 'model.diffusion_model.input_blocks.2.1.transformer_blocks.0.attn2.to_v.target_output', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_k.target_output', 'model.diffusion_model.input_blocks.4.1.transformer_blocks.0.attn2.to_v.target_output', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_k.target_output', 'model.diffusion_model.input_blocks.5.1.transformer_blocks.0.attn2.to_v.target_output', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_k.target_output', 'model.diffusion_model.input_blocks.7.1.transformer_blocks.0.attn2.to_v.target_output', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_k.target_output', 'model.diffusion_model.input_blocks.8.1.transformer_blocks.0.attn2.to_v.target_output', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_k.target_output', 'model.diffusion_model.middle_block.1.transformer_blocks.0.attn2.to_v.target_output', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_k.target_output', 'model.diffusion_model.output_blocks.3.1.transformer_blocks.0.attn2.to_v.target_output', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_k.target_output', 'model.diffusion_model.output_blocks.4.1.transformer_blocks.0.attn2.to_v.target_output', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_k.target_output', 'model.diffusion_model.output_blocks.5.1.transformer_blocks.0.attn2.to_v.target_output', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_k.target_output', 'model.diffusion_model.output_blocks.6.1.transformer_blocks.0.attn2.to_v.target_output', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_k.target_output', 'model.diffusion_model.output_blocks.7.1.transformer_blocks.0.attn2.to_v.target_output', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_k.target_output', 'model.diffusion_model.output_blocks.8.1.transformer_blocks.0.attn2.to_v.target_output', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_k.target_output', 'model.diffusion_model.output_blocks.9.1.transformer_blocks.0.attn2.to_v.target_output', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_k.target_output', 'model.diffusion_model.output_blocks.10.1.transformer_blocks.0.attn2.to_v.target_output', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_k.target_output', 'model.diffusion_model.output_blocks.11.1.transformer_blocks.0.attn2.to_v.target_output', 'embedding_manager.string_to_param_dict.*', 'embedding_manager.initial_embeddings.*']\n",
            "\n",
            "Unexpected Keys:\n",
            " ['model_ema.decay', 'model_ema.num_updates', 'cond_stage_model.transformer.text_model.embeddings.position_ids']\n",
            "Using 16bit native Automatic Mixed Precision (AMP)\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "accumulate_grad_batches = 4\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name              | Type               | Params\n",
            "---------------------------------------------------------\n",
            "0 | model             | DiffusionWrapper   | 861 M \n",
            "1 | first_stage_model | AutoencoderKL      | 83.7 M\n",
            "2 | cond_stage_model  | FrozenCLIPEmbedder | 123 M \n",
            "3 | embedding_manager | EmbeddingManager   | 1.5 K \n",
            "---------------------------------------------------------\n",
            "961 K     Trainable params\n",
            "1.1 B     Non-trainable params\n",
            "1.1 B     Total params\n",
            "2,136.318 Total estimated model params size (MB)\n",
            "Save project config\n",
            "Save lightning config\n",
            "Epoch 0:   0% 0/5000 [00:00<?, ?it/s]Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:02<02:23,  2.93s/it]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:03<01:12,  1.51s/it]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:03<00:49,  1.06s/it]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:04<00:39,  1.18it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:05<00:33,  1.36it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:05<00:29,  1.51it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:06<00:26,  1.62it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:06<00:24,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:07<00:23,  1.76it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:07<00:22,  1.80it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:08<00:21,  1.83it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:08<00:20,  1.85it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:09<00:19,  1.86it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:09<00:19,  1.87it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:10<00:18,  1.88it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:10<00:18,  1.88it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:11<00:17,  1.89it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:11<00:16,  1.89it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:12<00:16,  1.89it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:12<00:15,  1.89it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:13<00:15,  1.88it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:14<00:14,  1.88it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:14<00:14,  1.88it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:15<00:13,  1.88it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:15<00:13,  1.87it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:16<00:12,  1.88it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:16<00:12,  1.87it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:17<00:11,  1.88it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:17<00:11,  1.87it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:18<00:10,  1.87it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:18<00:10,  1.87it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:19<00:09,  1.87it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:19<00:09,  1.87it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:20<00:08,  1.87it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:20<00:08,  1.87it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:21<00:07,  1.87it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:22<00:06,  1.86it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:22<00:06,  1.86it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:23<00:05,  1.86it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:23<00:05,  1.86it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:24<00:04,  1.86it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:24<00:04,  1.85it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:25<00:03,  1.85it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:25<00:03,  1.85it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:26<00:02,  1.85it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:26<00:02,  1.85it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:27<00:01,  1.84it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:27<00:01,  1.84it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:28<00:00,  1.84it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:29<00:00,  1.72it/s]\n",
            "Epoch 0:   0% 20/5000 [01:26<5:58:59,  4.33s/it, loss=0.04, v_num=, train/loss_simple_step=0.0592, train/loss_vlb_step=0.000248, train/loss_step=0.0592, global_step=4.000]Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:27,  1.78it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:01<00:27,  1.76it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:01<00:26,  1.76it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:02<00:26,  1.75it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:02<00:25,  1.75it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:03<00:25,  1.75it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:03<00:24,  1.75it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:04<00:24,  1.74it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:05<00:23,  1.74it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:05<00:22,  1.75it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:06<00:22,  1.74it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:06<00:21,  1.74it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:07<00:21,  1.74it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:08<00:20,  1.74it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:08<00:20,  1.73it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:09<00:19,  1.74it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:09<00:19,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:10<00:18,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:10<00:17,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:11<00:17,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:12<00:16,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:12<00:16,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:13<00:15,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:13<00:15,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:14<00:14,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:15<00:14,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:15<00:13,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:16<00:12,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:16<00:12,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:17<00:11,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:17<00:11,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:18<00:10,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:19<00:09,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:19<00:09,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:20<00:08,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:20<00:08,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:21<00:07,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:22<00:07,  1.69it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:22<00:06,  1.69it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:23<00:05,  1.69it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:23<00:05,  1.70it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:24<00:04,  1.69it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:25<00:04,  1.69it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:25<00:03,  1.68it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:26<00:02,  1.68it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:26<00:02,  1.68it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:27<00:01,  1.68it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:28<00:01,  1.68it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:28<00:00,  1.68it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:29<00:00,  1.71it/s]\n",
            "Epoch 0:   2% 100/5000 [04:08<3:22:37,  2.48s/it, loss=0.0408, v_num=, train/loss_simple_step=0.058, train/loss_vlb_step=0.000222, train/loss_step=0.058, global_step=24.00] Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:28,  1.74it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:01<00:27,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:01<00:27,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:02<00:26,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:02<00:26,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:03<00:25,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:04<00:25,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:04<00:24,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:05<00:24,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:05<00:23,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:06<00:22,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:07<00:22,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:07<00:21,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:08<00:21,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:08<00:20,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:09<00:19,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:09<00:19,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:10<00:18,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:11<00:18,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:11<00:17,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:12<00:16,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:12<00:16,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:13<00:15,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:14<00:15,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:14<00:14,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:15<00:14,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:15<00:13,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:16<00:12,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:16<00:12,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:17<00:11,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:18<00:11,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:18<00:10,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:19<00:09,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:19<00:09,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:20<00:08,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:21<00:08,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:21<00:07,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:22<00:07,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:22<00:06,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:23<00:05,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:23<00:05,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:24<00:04,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:25<00:04,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:25<00:03,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:26<00:02,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:26<00:02,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:27<00:01,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:28<00:01,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:28<00:00,  1.72it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:29<00:00,  1.71it/s]\n",
            "Epoch 0:   4% 200/5000 [07:19<2:55:56,  2.20s/it, loss=0.0425, v_num=, train/loss_simple_step=0.0307, train/loss_vlb_step=0.000103, train/loss_step=0.0307, global_step=49.00]Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:28,  1.74it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:01<00:27,  1.73it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:01<00:27,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:02<00:26,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:02<00:26,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:03<00:25,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:04<00:25,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:04<00:24,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:05<00:23,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:05<00:23,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:06<00:22,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:06<00:22,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:07<00:21,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:08<00:21,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:08<00:20,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:09<00:19,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:09<00:19,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:10<00:18,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:11<00:18,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:11<00:17,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:12<00:16,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:12<00:16,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:13<00:15,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:14<00:15,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:14<00:14,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:15<00:14,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:15<00:13,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:16<00:12,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:16<00:12,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:17<00:11,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:18<00:11,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:18<00:10,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:19<00:09,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:19<00:09,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:20<00:08,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:21<00:08,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:21<00:07,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:22<00:07,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:22<00:06,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:23<00:05,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:23<00:05,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:24<00:04,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:25<00:04,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:25<00:03,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:26<00:02,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:26<00:02,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:27<00:01,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:28<00:01,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:28<00:00,  1.71it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:29<00:00,  1.71it/s]\n",
            "Epoch 0:   6% 300/5000 [10:32<2:45:15,  2.11s/it, loss=0.0339, v_num=, train/loss_simple_step=0.0334, train/loss_vlb_step=0.000134, train/loss_step=0.0334, global_step=74.00]Data shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\n",
            "DDIM Sampler:   2% 1/50 [00:00<00:28,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:   4% 2/50 [00:01<00:27,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:   6% 3/50 [00:01<00:27,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:   8% 4/50 [00:02<00:26,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  10% 5/50 [00:02<00:26,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  12% 6/50 [00:03<00:25,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  14% 7/50 [00:04<00:25,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  16% 8/50 [00:04<00:24,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  18% 9/50 [00:05<00:23,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  20% 10/50 [00:05<00:23,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  22% 11/50 [00:06<00:22,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  24% 12/50 [00:06<00:22,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  26% 13/50 [00:07<00:21,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  28% 14/50 [00:08<00:21,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  30% 15/50 [00:08<00:20,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  32% 16/50 [00:09<00:19,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  34% 17/50 [00:09<00:19,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  36% 18/50 [00:10<00:18,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  38% 19/50 [00:11<00:18,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  40% 20/50 [00:11<00:17,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  42% 21/50 [00:12<00:16,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  44% 22/50 [00:12<00:16,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  46% 23/50 [00:13<00:15,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  48% 24/50 [00:13<00:15,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  50% 25/50 [00:14<00:14,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  52% 26/50 [00:15<00:13,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  54% 27/50 [00:15<00:13,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  56% 28/50 [00:16<00:12,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  58% 29/50 [00:16<00:12,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  60% 30/50 [00:17<00:11,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  62% 31/50 [00:18<00:11,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  64% 32/50 [00:18<00:10,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  66% 33/50 [00:19<00:09,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  68% 34/50 [00:19<00:09,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  70% 35/50 [00:20<00:08,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  72% 36/50 [00:21<00:08,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  74% 37/50 [00:21<00:07,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  76% 38/50 [00:22<00:07,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  78% 39/50 [00:22<00:06,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  80% 40/50 [00:23<00:05,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  82% 41/50 [00:23<00:05,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  84% 42/50 [00:24<00:04,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  86% 43/50 [00:25<00:04,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  88% 44/50 [00:25<00:03,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  90% 45/50 [00:26<00:02,  1.72it/s]\u001b[A\n",
            "DDIM Sampler:  92% 46/50 [00:26<00:02,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  94% 47/50 [00:27<00:01,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  96% 48/50 [00:28<00:01,  1.71it/s]\u001b[A\n",
            "DDIM Sampler:  98% 49/50 [00:28<00:00,  1.71it/s]\u001b[A\n",
            "DDIM Sampler: 100% 50/50 [00:29<00:00,  1.71it/s]\n",
            "Epoch 0:   6% 320/5000 [11:40<2:50:37,  2.19s/it, loss=0.0438, v_num=, train/loss_simple_step=0.0573, train/loss_vlb_step=0.000664, train/loss_step=0.0573, global_step=79.00]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Change line 76 ./Key-Locked-Rank-One-Editing-for-Text-to-Image-Personalization/ldm/util.py\n",
        "%mkdir fonts\n",
        "%cd fonts\n",
        "!wget https://www.wfonts.com/download/data/2015/08/17/tiff-heavy/tiff-heavy.zip\n",
        "!unzip tiff-heavy.zip\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptaT4aw_Dag1",
        "outputId": "3acc157e-8f11-49b5-82da-e619fc9adf3f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  tiff-heavy.zip\n",
            "  inflating: TIFFH.ttf               \n",
            "  inflating: sharefonts.net.txt      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "n4uv01c4G0zT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! python scripts/perfusion_txt2img.py --ddim_eta 0.0 \\\n",
        "                                    --steps 50  \\\n",
        "                                    --scale 6.0 \\\n",
        "                                    --beta 0.7 \\\n",
        "                                    --tau 0.15 \\\n",
        "                                    --n_samples 4 \\\n",
        "                                    --n_iter 1 \\\n",
        "                                    --personalized_ckpt ./ckpt/teddy.ckpt \\\n",
        "                                    --prompt \"photo of a teddy* on a sofa\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EZ_IA9JGsDS",
        "outputId": "5482e598-0849-4e62-bd17-6f0d821282a8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-10-19 14:15:48.889277: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-10-19 14:15:48.920205: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-10-19 14:15:48.930095: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-10-19 14:15:50.981764: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Global seed set to 42\n",
            "Perfusion: Running in eps-prediction mode\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 1280, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 640, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is None and using 8 heads.\n",
            "Setting up MemoryEfficientCrossAttention. Query dim is 320, context_dim is 768 and using 8 heads.\n",
            "DiffusionWrapper has 861.44 M params.\n",
            "making attention of type 'vanilla-xformers' with 512 in_channels\n",
            "building MemoryEfficientAttnBlock with 512 in_channels...\n",
            "Working with z of shape (1, 4, 32, 32) = 4096 dimensions.\n",
            "making attention of type 'vanilla-xformers' with 512 in_channels\n",
            "building MemoryEfficientAttnBlock with 512 in_channels...\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Loading model from ./ckpt/v1-5-pruned-emaonly.ckpt and ./ckpt/teddy.ckpt\n",
            "Global Step: 840000\n",
            "Sampling:   0% 0/1 [00:00<?, ?it/s]\n",
            "data:   0% 0/1 [00:00<?, ?it/s]\u001b[AData shape for DDIM sampling is (4, 4, 64, 64), eta 0.0\n",
            "Running DDIM Sampling with 50 timesteps\n",
            "\n",
            "\n",
            "DDIM Sampler:   0% 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:   2% 1/50 [00:01<00:56,  1.15s/it]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:   4% 2/50 [00:01<00:37,  1.27it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:   6% 3/50 [00:02<00:31,  1.48it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:   8% 4/50 [00:02<00:28,  1.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  10% 5/50 [00:03<00:26,  1.68it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  12% 6/50 [00:03<00:25,  1.73it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  14% 7/50 [00:04<00:24,  1.76it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  16% 8/50 [00:04<00:23,  1.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  18% 9/50 [00:05<00:22,  1.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  20% 10/50 [00:06<00:22,  1.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  22% 11/50 [00:06<00:21,  1.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  24% 12/50 [00:07<00:20,  1.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  26% 13/50 [00:07<00:20,  1.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  28% 14/50 [00:08<00:19,  1.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  30% 15/50 [00:08<00:19,  1.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  32% 16/50 [00:09<00:18,  1.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  34% 17/50 [00:09<00:18,  1.83it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  36% 18/50 [00:10<00:17,  1.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  38% 19/50 [00:10<00:17,  1.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  40% 20/50 [00:11<00:16,  1.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  42% 21/50 [00:12<00:15,  1.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  44% 22/50 [00:12<00:15,  1.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  46% 23/50 [00:13<00:14,  1.82it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  48% 24/50 [00:13<00:14,  1.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  50% 25/50 [00:14<00:13,  1.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  52% 26/50 [00:14<00:13,  1.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  54% 27/50 [00:15<00:12,  1.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  56% 28/50 [00:15<00:12,  1.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  58% 29/50 [00:16<00:11,  1.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  60% 30/50 [00:17<00:11,  1.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  62% 31/50 [00:17<00:10,  1.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  64% 32/50 [00:18<00:10,  1.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  66% 33/50 [00:18<00:09,  1.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  68% 34/50 [00:19<00:08,  1.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  70% 35/50 [00:19<00:08,  1.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  72% 36/50 [00:20<00:07,  1.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  74% 37/50 [00:20<00:07,  1.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  76% 38/50 [00:21<00:06,  1.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  78% 39/50 [00:22<00:06,  1.80it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  80% 40/50 [00:22<00:05,  1.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  82% 41/50 [00:23<00:05,  1.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  84% 42/50 [00:23<00:04,  1.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  86% 43/50 [00:24<00:03,  1.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  88% 44/50 [00:24<00:03,  1.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  90% 45/50 [00:25<00:02,  1.79it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  92% 46/50 [00:25<00:02,  1.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  94% 47/50 [00:26<00:01,  1.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  96% 48/50 [00:27<00:01,  1.77it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler:  98% 49/50 [00:27<00:00,  1.78it/s]\u001b[A\u001b[A\n",
            "\n",
            "DDIM Sampler: 100% 50/50 [00:28<00:00,  1.77it/s]\n",
            "\n",
            "data: 100% 1/1 [00:29<00:00, 29.61s/it]\n",
            "Sampling: 100% 1/1 [00:29<00:00, 29.61s/it]\n",
            "Your samples are ready and waiting for you here: \n",
            "outputs/txt2img-samples \n",
            " \n",
            "Enjoy.\n"
          ]
        }
      ]
    }
  ]
}